{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Predição de divergências em notas fiscais usando Python e Machine Learning",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Nesse projeto, será criado um modelo de Machine Learning baseado na técnica Support Vector Machine (SVM) para prever se a emissão de uma nota fiscal possuirá alguma divergência ou não baseado no tipo do processo, hora de emissão, dia da semana da emissão e valor da nota.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Importando as bibliotecas",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Antes de tudo, iremos importar as bibliotecas necessárias para nosso projeto:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn.metrics import accuracy_score",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Coleta de Dados e Análise",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Agora, vamos carregar o banco de dados das notas fiscais para o projeto:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "notafiscal_dataset = pd.read_csv('notafiscal (3).csv')\nnotafiscal_dataset.head(5)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 42,
      "outputs": [
        {
          "execution_count": 42,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   tipo_processo  valor_nota  horario_criacao  dia_semana  divergencia\n0              1       201.7              754           4            1\n1              1       423.7              707           6            0\n2              5       113.0              568           4            0\n3              4       119.0              186           7            0\n4              2       161.7              656           7            1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tipo_processo</th>\n      <th>valor_nota</th>\n      <th>horario_criacao</th>\n      <th>dia_semana</th>\n      <th>divergencia</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>201.7</td>\n      <td>754</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>423.7</td>\n      <td>707</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>113.0</td>\n      <td>568</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>119.0</td>\n      <td>186</td>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>161.7</td>\n      <td>656</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "notafiscal_dataset.shape",
      "metadata": {
        "trusted": true
      },
      "execution_count": 43,
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(768, 5)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Agora, iremos obter dados estatísticos sobre o banco:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "notafiscal_dataset.describe()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 44,
      "outputs": [
        {
          "execution_count": 44,
          "output_type": "execute_result",
          "data": {
            "text/plain": "       tipo_processo  valor_nota  horario_criacao  dia_semana  divergencia\ncount     768.000000  768.000000       768.000000  768.000000   768.000000\nmean        2.540365  388.581510       519.687500    3.947917     0.447917\nstd         1.250162  259.696051       367.335228    1.966445     0.497604\nmin         1.000000    0.100000         1.000000    1.000000     0.000000\n25%         2.000000  187.400000       227.250000    2.000000     0.000000\n50%         2.000000  343.800000       455.500000    4.000000     0.000000\n75%         3.000000  544.900000       704.250000    6.000000     1.000000\nmax         5.000000  999.400000      1437.000000    7.000000     1.000000",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tipo_processo</th>\n      <th>valor_nota</th>\n      <th>horario_criacao</th>\n      <th>dia_semana</th>\n      <th>divergencia</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.540365</td>\n      <td>388.581510</td>\n      <td>519.687500</td>\n      <td>3.947917</td>\n      <td>0.447917</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.250162</td>\n      <td>259.696051</td>\n      <td>367.335228</td>\n      <td>1.966445</td>\n      <td>0.497604</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.100000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>187.400000</td>\n      <td>227.250000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.000000</td>\n      <td>343.800000</td>\n      <td>455.500000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>544.900000</td>\n      <td>704.250000</td>\n      <td>6.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.000000</td>\n      <td>999.400000</td>\n      <td>1437.000000</td>\n      <td>7.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Analisando a distribuição dos valores de saída:\n    \n    0 = Não apresenta divergência\n    1 = Apresenta divergência",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "notafiscal_dataset['divergencia'].value_counts()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 45,
      "outputs": [
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0    424\n1    344\nName: divergencia, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Agora, iremos obter a média dos valores de cada atributo do banco de dados, agrupando por diferentes saídas:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "notafiscal_dataset.groupby('divergencia').mean()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 46,
      "outputs": [
        {
          "execution_count": 46,
          "output_type": "execute_result",
          "data": {
            "text/plain": "             tipo_processo  valor_nota  horario_criacao  dia_semana\ndivergencia                                                        \n0                 2.969340  497.035377       365.313679    3.886792\n1                 2.011628  254.905814       709.962209    4.023256",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tipo_processo</th>\n      <th>valor_nota</th>\n      <th>horario_criacao</th>\n      <th>dia_semana</th>\n    </tr>\n    <tr>\n      <th>divergencia</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.969340</td>\n      <td>497.035377</td>\n      <td>365.313679</td>\n      <td>3.886792</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.011628</td>\n      <td>254.905814</td>\n      <td>709.962209</td>\n      <td>4.023256</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Analisando a média dos atributos obtida, podemos ver que existe uma correlação entre diferentes variáveis com a saída, como o tipo do processo, valor da nota e horario de criação.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Agora iremos separar os dados da saída e imprimir ambos:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X = notafiscal_dataset.drop(columns = 'divergencia', axis=1)\nY = notafiscal_dataset['divergencia']\nprint(X)\nprint(Y)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 48,
      "outputs": [
        {
          "name": "stdout",
          "text": "     tipo_processo  valor_nota  horario_criacao  dia_semana\n0                1       201.7              754           4\n1                1       423.7              707           6\n2                5       113.0              568           4\n3                4       119.0              186           7\n4                2       161.7              656           7\n..             ...         ...              ...         ...\n763              3        56.5              726           3\n764              2       987.3              101           6\n765              4       411.8               77           5\n766              1       257.3              696           1\n767              2       670.7              218           2\n\n[768 rows x 4 columns]\n0      1\n1      0\n2      0\n3      0\n4      1\n      ..\n763    0\n764    0\n765    0\n766    1\n767    0\nName: divergencia, Length: 768, dtype: int64\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Padronização dos Dados",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Como as variáveis possuem diferentes escalas, devemos padronizá-las para podermos realizar previsões:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scaler = StandardScaler()\nX = np.asarray(X)\nscaler.fit(X)\nstandardized_data = scaler.transform(X)\nX = standardized_data\nX",
      "metadata": {
        "trusted": true
      },
      "execution_count": 49,
      "outputs": [
        {
          "execution_count": 49,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[-1.23293466, -0.72008526,  0.63828672,  0.0265033 ],\n       [-1.23293466,  0.13531733,  0.51025481,  1.04422992],\n       [ 1.96873505, -1.06186097,  0.13160726,  0.0265033 ],\n       ...,\n       [ 1.16831762,  0.08946467, -1.20591753,  0.53536661],\n       [-1.23293466, -0.50584929,  0.4802899 , -1.50008663],\n       [-0.43251723,  1.08704903, -0.82182181, -0.99122332]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Agora, todos os parâmetros estão em uma escala similar.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Train Test Split",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Nesta parte, precisamos dividir nossos dados em sets de treino e de teste para nosso modelo.\n\nNossos dados de teste terão 20% do banco de dados e os dados de treino terão 80% do banco de dados.\n\nO parâmetro \"stratify\" éutilizado para balancear a divisão dos dados de maneira proporcional às saídas.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify=Y, random_state = 2)\nprint(X.shape, X_train.shape, X_test.shape)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 50,
      "outputs": [
        {
          "name": "stdout",
          "text": "(768, 4) (614, 4) (154, 4)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Treinando o modelo",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Agora, iremos treinar o modelo com os dados de treino obtidos na última seção:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "classifier = svm.SVC(kernel='linear')\nclassifier.fit(X_train, Y_train)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 51,
      "outputs": [
        {
          "execution_count": 51,
          "output_type": "execute_result",
          "data": {
            "text/plain": "SVC(kernel='linear')",
            "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Avaliação do modelo",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Agora, iremos avaliar o nosso modelo:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train_prediction = classifier.predict(X_train)\ntraining_data_accuracy = accuracy_score(X_train_prediction, Y_train)\nprint('Precisão dos dados de treino: ', training_data_accuracy)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 54,
      "outputs": [
        {
          "name": "stdout",
          "text": "Precisão dos dados de treino:  0.7833876221498371\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Com esse resultado podemos perceber que a precisão do modelo é de 78.34%, o que pode ser considerado um bom (mas não ótimo) resultado.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Agora, iremos examinar a precisão do nosso modelo performando em cima de dados que não foram utilizados ainda, os dados de teste:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_test_prediction = classifier.predict(X_test)\ntest_data_accuracy = accuracy_score(X_test_prediction, Y_test)\nprint('Precisão dos dados de teste: ', test_data_accuracy)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 55,
      "outputs": [
        {
          "name": "stdout",
          "text": "Precisão dos dados de teste:  0.8311688311688312\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "Agora, podemos ver que a precisão do modelo é de 83,11% quando submetido ao set de teste, o que representa uma precisão ainda maior do que a obtida com o set de treinamento. Isso representa um resultado muito bom.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Criando um sistema de previsões",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Agora, iremos criar um sistema capaz de prever com certo grau de precisão se a emissão de uma nota fiscal será sucedida de uma divergência ou não, baseado nos dados de entrada.\n\nPara isso, iremos usar os dados de uma nota fiscal cuja qual já sabemos a saída.\n\nExemplo: 3,609.2,720,5,0\n\nO 0 no final nos mostra que a emissão dessa nota fiscal não foi sucedida de uma divergência. Obviamente, essa informação não será usada em nosso sistema.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "input_data = (3,609.2,720,5)\ninput_data_array = np.asarray(input_data) # Mudando dados de enrada para formato de array\ninput_data_reshaped = input_data_array.reshape(1, -1) # Mudando os dados de formato, já que vamos prever só um caso\nstandardized_data = scaler.transform(input_data_reshaped) # Padronizando os dados para coincidirem com o modelo\nprediction = classifier.predict(standardized_data) # Prevendo a saída\nif prediction[0] == 0:\n    print(\"Nota fiscal não deve apresentar divergências.\")\nelse:\n    print(\"Nota fiscal deve apresentar divergências.\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": 57,
      "outputs": [
        {
          "name": "stdout",
          "text": "Nota fiscal não deve apresentar divergências.\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}